{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data = pd.read_csv('data/training.csv')\n",
    "m_data = data.shape[0]\n",
    "df_train, df_test = data[0:int(0.7*m_data)], data[int(0.7*m_data)+1:m_data]\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "df = pd.read_csv('data/race-result-horse.csv')\n",
    "m, n = np.shape(df)\n",
    "m_train, _ = np.shape(df_train)\n",
    "m_test, _ = np.shape(df_test)\n",
    "\n",
    "#produce dicts for horse,jockey,trainer\n",
    "horse=list()\n",
    "jockey=list()\n",
    "trainer=list()\n",
    "for i in range(len(df)):\n",
    "    if df.horse_name[i] not in horse:\n",
    "        horse.append(df.horse_name[i])\n",
    "    if df.jockey[i] not in jockey:\n",
    "        jockey.append(df.jockey[i])\n",
    "    if df.trainer[i] not in jockey:\n",
    "        trainer.append(df.trainer[i])\n",
    "train_horse=np.zeros((m_train,1))\n",
    "train_jockey=np.zeros((m_train,1))\n",
    "train_trainer=np.zeros((m_train,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finishing_position</th>\n",
       "      <th>horse_number</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey</th>\n",
       "      <th>trainer</th>\n",
       "      <th>actual_weight</th>\n",
       "      <th>declared_horse_weight</th>\n",
       "      <th>draw</th>\n",
       "      <th>length_behind_winner</th>\n",
       "      <th>...</th>\n",
       "      <th>finish_time</th>\n",
       "      <th>win_odds</th>\n",
       "      <th>running_position_5</th>\n",
       "      <th>running_position_6</th>\n",
       "      <th>race_id</th>\n",
       "      <th>recent_6_runs</th>\n",
       "      <th>recent_ave_rank</th>\n",
       "      <th>jockey_ave_rank</th>\n",
       "      <th>trainer_ave_rank</th>\n",
       "      <th>race_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PADDINGTON</td>\n",
       "      <td>A107</td>\n",
       "      <td>A Badel</td>\n",
       "      <td>W Y So</td>\n",
       "      <td>125</td>\n",
       "      <td>1144</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57.79</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CHEER WIN</td>\n",
       "      <td>V347</td>\n",
       "      <td>K K Chiong</td>\n",
       "      <td>P F Yiu</td>\n",
       "      <td>128</td>\n",
       "      <td>1124</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57.82</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>4/11/2/1/5/8</td>\n",
       "      <td>5.17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BEAUTY CONNECTION</td>\n",
       "      <td>T415</td>\n",
       "      <td>J Moreira</td>\n",
       "      <td>A S Cruz</td>\n",
       "      <td>133</td>\n",
       "      <td>1131</td>\n",
       "      <td>9</td>\n",
       "      <td>2-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58.07</td>\n",
       "      <td>5.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>12/12/4/2/9/4</td>\n",
       "      <td>7.17</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SECRET AGENT</td>\n",
       "      <td>P388</td>\n",
       "      <td>S de Sousa</td>\n",
       "      <td>K L Man</td>\n",
       "      <td>132</td>\n",
       "      <td>1064</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58.12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>2/9/3/4/1/3</td>\n",
       "      <td>3.67</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>ST YAZIN</td>\n",
       "      <td>N409</td>\n",
       "      <td>O Murphy</td>\n",
       "      <td>T K Ng</td>\n",
       "      <td>121</td>\n",
       "      <td>1075</td>\n",
       "      <td>5</td>\n",
       "      <td>3-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58.18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>9/1/6/1/9/5</td>\n",
       "      <td>5.17</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>OCEAN ROAR</td>\n",
       "      <td>N317</td>\n",
       "      <td>M L Yeung</td>\n",
       "      <td>A Lee</td>\n",
       "      <td>130</td>\n",
       "      <td>1203</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58.28</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>11/11/8/10/9/12</td>\n",
       "      <td>10.17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>WINFULL PATROL</td>\n",
       "      <td>P063</td>\n",
       "      <td>K C Leung</td>\n",
       "      <td>R Gibson</td>\n",
       "      <td>129</td>\n",
       "      <td>1237</td>\n",
       "      <td>2</td>\n",
       "      <td>5-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58.48</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>10/11/9/10/4/2</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>FANTASTIC FABIO</td>\n",
       "      <td>V364</td>\n",
       "      <td>C Y Ho</td>\n",
       "      <td>C H Yip</td>\n",
       "      <td>114</td>\n",
       "      <td>1141</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59.11</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>11/10/12/7/9</td>\n",
       "      <td>9.80</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LYRIC ACE</td>\n",
       "      <td>S047</td>\n",
       "      <td>K C Ng</td>\n",
       "      <td>D Cruz</td>\n",
       "      <td>123</td>\n",
       "      <td>1071</td>\n",
       "      <td>7</td>\n",
       "      <td>15-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00.08</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-327</td>\n",
       "      <td>11/5/1/7/10/2</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>POWERMAX</td>\n",
       "      <td>A009</td>\n",
       "      <td>N Callan</td>\n",
       "      <td>R Gibson</td>\n",
       "      <td>126</td>\n",
       "      <td>1124</td>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10.69</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>4/3/3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BUDDY BUNDY</td>\n",
       "      <td>T157</td>\n",
       "      <td>K K Chiong</td>\n",
       "      <td>D Cruz</td>\n",
       "      <td>127</td>\n",
       "      <td>1193</td>\n",
       "      <td>8</td>\n",
       "      <td>SH</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10.70</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>11/5/2/6/9/8</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>ROYALE ELEGANCE</td>\n",
       "      <td>S098</td>\n",
       "      <td>O Murphy</td>\n",
       "      <td>W Y So</td>\n",
       "      <td>131</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10.76</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>2/4/4/5/7/5</td>\n",
       "      <td>4.50</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>CONFUCIUS SPIRIT</td>\n",
       "      <td>S329</td>\n",
       "      <td>K Teetan</td>\n",
       "      <td>D E Ferraris</td>\n",
       "      <td>120</td>\n",
       "      <td>1073</td>\n",
       "      <td>2</td>\n",
       "      <td>1-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10.89</td>\n",
       "      <td>5.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>3/5/8/2/4/3</td>\n",
       "      <td>4.17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>STARLIGHT</td>\n",
       "      <td>V273</td>\n",
       "      <td>Z Purton</td>\n",
       "      <td>C H Yip</td>\n",
       "      <td>122</td>\n",
       "      <td>1056</td>\n",
       "      <td>12</td>\n",
       "      <td>1-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10.91</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>6/14/12</td>\n",
       "      <td>10.67</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>PEARL WIN</td>\n",
       "      <td>P085</td>\n",
       "      <td>C Schofield</td>\n",
       "      <td>A T Millard</td>\n",
       "      <td>122</td>\n",
       "      <td>1064</td>\n",
       "      <td>3</td>\n",
       "      <td>1-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10.91</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>9/6/7/4/4/4</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>SMART SALUTE</td>\n",
       "      <td>V117</td>\n",
       "      <td>M Chadwick</td>\n",
       "      <td>Y S Tsui</td>\n",
       "      <td>115</td>\n",
       "      <td>1109</td>\n",
       "      <td>5</td>\n",
       "      <td>1-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10.92</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>6/2/8/9/4/12</td>\n",
       "      <td>6.83</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PAKISTAN BABY</td>\n",
       "      <td>S442</td>\n",
       "      <td>S de Sousa</td>\n",
       "      <td>A S Cruz</td>\n",
       "      <td>133</td>\n",
       "      <td>1025</td>\n",
       "      <td>7</td>\n",
       "      <td>1-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.10.95</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>2/8/10/6/6/5</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>FORMULA GALORE</td>\n",
       "      <td>V011</td>\n",
       "      <td>J Moreira</td>\n",
       "      <td>C Fownes</td>\n",
       "      <td>123</td>\n",
       "      <td>1102</td>\n",
       "      <td>10</td>\n",
       "      <td>4-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11.41</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>11/1/2/3/6/7</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>GREAT WISDOM</td>\n",
       "      <td>V084</td>\n",
       "      <td>A Badel</td>\n",
       "      <td>K L Man</td>\n",
       "      <td>123</td>\n",
       "      <td>1074</td>\n",
       "      <td>6</td>\n",
       "      <td>8-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12.03</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>8/10</td>\n",
       "      <td>9.00</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>WHISTLE UP</td>\n",
       "      <td>A082</td>\n",
       "      <td>K C Leung</td>\n",
       "      <td>L Ho</td>\n",
       "      <td>124</td>\n",
       "      <td>1156</td>\n",
       "      <td>11</td>\n",
       "      <td>9-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12.19</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>DOUBLE DOUBLE</td>\n",
       "      <td>T267</td>\n",
       "      <td>C Y Ho</td>\n",
       "      <td>T K Ng</td>\n",
       "      <td>124</td>\n",
       "      <td>1080</td>\n",
       "      <td>4</td>\n",
       "      <td>13-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.12.82</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-328</td>\n",
       "      <td>12</td>\n",
       "      <td>12.00</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GIANT TURTLE</td>\n",
       "      <td>T391</td>\n",
       "      <td>C Schofield</td>\n",
       "      <td>A T Millard</td>\n",
       "      <td>130</td>\n",
       "      <td>1025</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>1.40.62</td>\n",
       "      <td>3.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>1/2/2/7/4/6</td>\n",
       "      <td>3.67</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SPARKLING SWORD</td>\n",
       "      <td>P256</td>\n",
       "      <td>K K Chiong</td>\n",
       "      <td>K W Lui</td>\n",
       "      <td>123</td>\n",
       "      <td>1175</td>\n",
       "      <td>7</td>\n",
       "      <td>2-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.40.96</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>10/2/2/2/7/10</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>LUCKY PROFIT</td>\n",
       "      <td>S335</td>\n",
       "      <td>A Badel</td>\n",
       "      <td>C S Shum</td>\n",
       "      <td>132</td>\n",
       "      <td>1137</td>\n",
       "      <td>3</td>\n",
       "      <td>2-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41.01</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>10/12/10/12/6/2</td>\n",
       "      <td>8.67</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WORKS OF ART</td>\n",
       "      <td>V212</td>\n",
       "      <td>J Moreira</td>\n",
       "      <td>J Size</td>\n",
       "      <td>131</td>\n",
       "      <td>1110</td>\n",
       "      <td>6</td>\n",
       "      <td>2-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41.04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>4/1/3/13/11</td>\n",
       "      <td>6.40</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NEWSWIRE FREE</td>\n",
       "      <td>S407</td>\n",
       "      <td>S de Sousa</td>\n",
       "      <td>P F Yiu</td>\n",
       "      <td>124</td>\n",
       "      <td>1108</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41.41</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>7/7/6/1/2/3</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TRAVEL AMBASSADOR</td>\n",
       "      <td>T113</td>\n",
       "      <td>B Prebble</td>\n",
       "      <td>W Y So</td>\n",
       "      <td>124</td>\n",
       "      <td>1128</td>\n",
       "      <td>12</td>\n",
       "      <td>5-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41.47</td>\n",
       "      <td>8.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>3/1/6/3/6/8</td>\n",
       "      <td>4.50</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GRAND HARBOUR</td>\n",
       "      <td>P421</td>\n",
       "      <td>M Chadwick</td>\n",
       "      <td>C W Chang</td>\n",
       "      <td>133</td>\n",
       "      <td>1190</td>\n",
       "      <td>4</td>\n",
       "      <td>5-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41.51</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>9/5/2/12/2/12</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>GREAT TOPLIGHT</td>\n",
       "      <td>T031</td>\n",
       "      <td>O Doleuze</td>\n",
       "      <td>C Fownes</td>\n",
       "      <td>123</td>\n",
       "      <td>1068</td>\n",
       "      <td>9</td>\n",
       "      <td>5-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41.55</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>4/6/8/3/6/4</td>\n",
       "      <td>5.17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>EXCELLENCE</td>\n",
       "      <td>T314</td>\n",
       "      <td>Z Purton</td>\n",
       "      <td>A Lee</td>\n",
       "      <td>120</td>\n",
       "      <td>1047</td>\n",
       "      <td>8</td>\n",
       "      <td>6-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41.62</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-329</td>\n",
       "      <td>1/9/12/7/6/9</td>\n",
       "      <td>7.33</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>FIRST FONTEIN</td>\n",
       "      <td>V361</td>\n",
       "      <td>M L Yeung</td>\n",
       "      <td>W Y So</td>\n",
       "      <td>114</td>\n",
       "      <td>1100</td>\n",
       "      <td>5</td>\n",
       "      <td>5-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36.87</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>7/8/4/12/6/6</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>SMILING CHARM</td>\n",
       "      <td>V321</td>\n",
       "      <td>D Whyte</td>\n",
       "      <td>C W Chang</td>\n",
       "      <td>122</td>\n",
       "      <td>1141</td>\n",
       "      <td>8</td>\n",
       "      <td>6-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36.98</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>9/2/2/4/6/6</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>DEJA VU</td>\n",
       "      <td>T376</td>\n",
       "      <td>H N Wong</td>\n",
       "      <td>A Lee</td>\n",
       "      <td>112</td>\n",
       "      <td>1233</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37.06</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>5/5/5/7/5/6</td>\n",
       "      <td>5.50</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>WINWIN RUBY</td>\n",
       "      <td>A120</td>\n",
       "      <td>N Callan</td>\n",
       "      <td>K L Man</td>\n",
       "      <td>129</td>\n",
       "      <td>1036</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37.08</td>\n",
       "      <td>4.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>1/8/6/4/14</td>\n",
       "      <td>6.60</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>WHOOP WHOOP</td>\n",
       "      <td>A096</td>\n",
       "      <td>A Sanna</td>\n",
       "      <td>C H Yip</td>\n",
       "      <td>121</td>\n",
       "      <td>1203</td>\n",
       "      <td>2</td>\n",
       "      <td>8-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37.27</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>11/14/5/13</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848</th>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>UNICORN</td>\n",
       "      <td>T046</td>\n",
       "      <td>K K Chiong</td>\n",
       "      <td>C S Shum</td>\n",
       "      <td>127</td>\n",
       "      <td>1078</td>\n",
       "      <td>7</td>\n",
       "      <td>9-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37.42</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>4/3/2/3/8/1</td>\n",
       "      <td>3.50</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5849</th>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>GOLD LAND</td>\n",
       "      <td>A109</td>\n",
       "      <td>C Y Ho</td>\n",
       "      <td>A S Cruz</td>\n",
       "      <td>129</td>\n",
       "      <td>1146</td>\n",
       "      <td>13</td>\n",
       "      <td>9-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37.50</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>8/7/10/8/11/11</td>\n",
       "      <td>9.17</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LET US WIN</td>\n",
       "      <td>V381</td>\n",
       "      <td>S Clipperton</td>\n",
       "      <td>J Moore</td>\n",
       "      <td>133</td>\n",
       "      <td>1120</td>\n",
       "      <td>10</td>\n",
       "      <td>10-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37.61</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>10/4/3/9/14/9</td>\n",
       "      <td>8.17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5851</th>\n",
       "      <td>14</td>\n",
       "      <td>12.0</td>\n",
       "      <td>PRETTY BAUHINIA</td>\n",
       "      <td>A135</td>\n",
       "      <td>U Rispoli</td>\n",
       "      <td>Y S Tsui</td>\n",
       "      <td>121</td>\n",
       "      <td>1017</td>\n",
       "      <td>12</td>\n",
       "      <td>31-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41.03</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-803</td>\n",
       "      <td>10/7/7/4/9</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>TIME WARP</td>\n",
       "      <td>A066</td>\n",
       "      <td>K C Ng</td>\n",
       "      <td>A S Cruz</td>\n",
       "      <td>112</td>\n",
       "      <td>1198</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>1.35.39</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-804</td>\n",
       "      <td>1/1/7/4/6/3</td>\n",
       "      <td>3.67</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>BOOMING DELIGHT</td>\n",
       "      <td>A113</td>\n",
       "      <td>S Clipperton</td>\n",
       "      <td>J Moore</td>\n",
       "      <td>123</td>\n",
       "      <td>1183</td>\n",
       "      <td>8</td>\n",
       "      <td>1-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.35.67</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-804</td>\n",
       "      <td>1/2/2/8/1/1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BEAT THE CLOCK</td>\n",
       "      <td>V397</td>\n",
       "      <td>J Moreira</td>\n",
       "      <td>J Size</td>\n",
       "      <td>117</td>\n",
       "      <td>1092</td>\n",
       "      <td>3</td>\n",
       "      <td>3-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.35.94</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-804</td>\n",
       "      <td>1/1/2/1/3/2</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5855</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ROMANTIC TOUCH</td>\n",
       "      <td>S393</td>\n",
       "      <td>D Whyte</td>\n",
       "      <td>A S Cruz</td>\n",
       "      <td>128</td>\n",
       "      <td>1171</td>\n",
       "      <td>5</td>\n",
       "      <td>3-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36.00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-804</td>\n",
       "      <td>2/6/3/3/8/2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>KING GENKI</td>\n",
       "      <td>V181</td>\n",
       "      <td>K Teetan</td>\n",
       "      <td>A S Cruz</td>\n",
       "      <td>113</td>\n",
       "      <td>1259</td>\n",
       "      <td>6</td>\n",
       "      <td>4-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36.06</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-804</td>\n",
       "      <td>11/1/1/3/7/2</td>\n",
       "      <td>4.17</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>SUPREME PROFIT</td>\n",
       "      <td>P230</td>\n",
       "      <td>M F Poon</td>\n",
       "      <td>C S Shum</td>\n",
       "      <td>108</td>\n",
       "      <td>1279</td>\n",
       "      <td>4</td>\n",
       "      <td>6-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36.38</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-804</td>\n",
       "      <td>9/3/7/9/12/10</td>\n",
       "      <td>8.33</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HORSE OF FORTUNE</td>\n",
       "      <td>T118</td>\n",
       "      <td>C Murray</td>\n",
       "      <td>A T Millard</td>\n",
       "      <td>133</td>\n",
       "      <td>1094</td>\n",
       "      <td>7</td>\n",
       "      <td>6-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36.40</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-804</td>\n",
       "      <td>1/2/9/10/8/6</td>\n",
       "      <td>6.00</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ANTICIPATION</td>\n",
       "      <td>T198</td>\n",
       "      <td>M L Yeung</td>\n",
       "      <td>A S Cruz</td>\n",
       "      <td>112</td>\n",
       "      <td>1129</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.37.80</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-804</td>\n",
       "      <td>2/13/8/5/11/14</td>\n",
       "      <td>8.83</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>CALCULATION</td>\n",
       "      <td>A248</td>\n",
       "      <td>J Moreira</td>\n",
       "      <td>J Size</td>\n",
       "      <td>120</td>\n",
       "      <td>1076</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23.09</td>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>CHUNG WAH SPIRIT</td>\n",
       "      <td>A168</td>\n",
       "      <td>Z Purton</td>\n",
       "      <td>C H Yip</td>\n",
       "      <td>129</td>\n",
       "      <td>1119</td>\n",
       "      <td>8</td>\n",
       "      <td>1-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23.36</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>4/1/7/3/7</td>\n",
       "      <td>4.40</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>FANTASTIC KAKA</td>\n",
       "      <td>P363</td>\n",
       "      <td>A Sanna</td>\n",
       "      <td>L Ho</td>\n",
       "      <td>127</td>\n",
       "      <td>1128</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23.51</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>7/4/14/9/2/11</td>\n",
       "      <td>7.83</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>RIGHT HONOURABLE</td>\n",
       "      <td>A164</td>\n",
       "      <td>M L Yeung</td>\n",
       "      <td>R Gibson</td>\n",
       "      <td>114</td>\n",
       "      <td>1010</td>\n",
       "      <td>6</td>\n",
       "      <td>4-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23.74</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>8/3/7/11/12</td>\n",
       "      <td>8.20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>QUICK RETURN</td>\n",
       "      <td>A286</td>\n",
       "      <td>U Rispoli</td>\n",
       "      <td>C S Shum</td>\n",
       "      <td>122</td>\n",
       "      <td>1117</td>\n",
       "      <td>5</td>\n",
       "      <td>4-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23.74</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>10/6/5</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SUNNY WAY</td>\n",
       "      <td>V176</td>\n",
       "      <td>S Clipperton</td>\n",
       "      <td>J Moore</td>\n",
       "      <td>131</td>\n",
       "      <td>1053</td>\n",
       "      <td>14</td>\n",
       "      <td>4-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23.76</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>4/3/5/2/1/12</td>\n",
       "      <td>4.50</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>GOLDEN SLEEP</td>\n",
       "      <td>T117</td>\n",
       "      <td>K K Chiong</td>\n",
       "      <td>C H Yip</td>\n",
       "      <td>117</td>\n",
       "      <td>1170</td>\n",
       "      <td>10</td>\n",
       "      <td>4-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23.79</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>1/11/10/11/5/6</td>\n",
       "      <td>7.33</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>WORLD RECORD</td>\n",
       "      <td>V040</td>\n",
       "      <td>C Murray</td>\n",
       "      <td>A T Millard</td>\n",
       "      <td>127</td>\n",
       "      <td>1073</td>\n",
       "      <td>4</td>\n",
       "      <td>5-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.23.98</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>3/4/3/1/11/2</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>INTREPIC</td>\n",
       "      <td>A139</td>\n",
       "      <td>M F Poon</td>\n",
       "      <td>D J Hall</td>\n",
       "      <td>116</td>\n",
       "      <td>993</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24.05</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>1/2/12/13/13/6</td>\n",
       "      <td>7.83</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>10</td>\n",
       "      <td>12.0</td>\n",
       "      <td>HIGH AND MIGHTY</td>\n",
       "      <td>S362</td>\n",
       "      <td>D Whyte</td>\n",
       "      <td>W Y So</td>\n",
       "      <td>119</td>\n",
       "      <td>1132</td>\n",
       "      <td>11</td>\n",
       "      <td>6-3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24.18</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>5/3/9/8/9/9</td>\n",
       "      <td>7.17</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DOUBLE VALENTINE</td>\n",
       "      <td>A163</td>\n",
       "      <td>B Prebble</td>\n",
       "      <td>A S Cruz</td>\n",
       "      <td>127</td>\n",
       "      <td>1085</td>\n",
       "      <td>13</td>\n",
       "      <td>9-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24.58</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>8/11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>THE JOY OF GIVING</td>\n",
       "      <td>A249</td>\n",
       "      <td>W M Lai</td>\n",
       "      <td>C W Chang</td>\n",
       "      <td>122</td>\n",
       "      <td>1026</td>\n",
       "      <td>9</td>\n",
       "      <td>13-1/2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.25.26</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>12/10</td>\n",
       "      <td>11.00</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>MIGHTY BOY</td>\n",
       "      <td>A352</td>\n",
       "      <td>N Callan</td>\n",
       "      <td>J Moore</td>\n",
       "      <td>126</td>\n",
       "      <td>1153</td>\n",
       "      <td>1</td>\n",
       "      <td>14-1/4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.25.35</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5873 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      finishing_position  horse_number         horse_name horse_id  \\\n",
       "0                      3          10.0         PADDINGTON     A107   \n",
       "1                      4           2.0          CHEER WIN     V347   \n",
       "2                      5           1.0  BEAUTY CONNECTION     T415   \n",
       "3                      6           5.0       SECRET AGENT     P388   \n",
       "4                      7          11.0           ST YAZIN     N409   \n",
       "5                      8           4.0         OCEAN ROAR     N317   \n",
       "6                      9           7.0     WINFULL PATROL     P063   \n",
       "7                     10          12.0    FANTASTIC FABIO     V364   \n",
       "8                     11           8.0          LYRIC ACE     S047   \n",
       "9                      1           5.0           POWERMAX     A009   \n",
       "10                     2           2.0        BUDDY BUNDY     T157   \n",
       "11                     3           3.0    ROYALE ELEGANCE     S098   \n",
       "12                     4          11.0   CONFUCIUS SPIRIT     S329   \n",
       "13                     5          10.0          STARLIGHT     V273   \n",
       "14                     6           9.0          PEARL WIN     P085   \n",
       "15                     7          12.0       SMART SALUTE     V117   \n",
       "16                     8           1.0      PAKISTAN BABY     S442   \n",
       "17                     9           7.0     FORMULA GALORE     V011   \n",
       "18                    10           8.0       GREAT WISDOM     V084   \n",
       "19                    11           6.0         WHISTLE UP     A082   \n",
       "20                    12           4.0      DOUBLE DOUBLE     T267   \n",
       "21                     1           4.0       GIANT TURTLE     T391   \n",
       "22                     2           5.0    SPARKLING SWORD     P256   \n",
       "23                     3           2.0       LUCKY PROFIT     S335   \n",
       "24                     4           3.0       WORKS OF ART     V212   \n",
       "25                     5           7.0      NEWSWIRE FREE     S407   \n",
       "26                     6           8.0  TRAVEL AMBASSADOR     T113   \n",
       "27                     7           1.0      GRAND HARBOUR     P421   \n",
       "28                     8          10.0     GREAT TOPLIGHT     T031   \n",
       "29                     9          11.0         EXCELLENCE     T314   \n",
       "...                  ...           ...                ...      ...   \n",
       "5843                   6          14.0      FIRST FONTEIN     V361   \n",
       "5844                   7          11.0      SMILING CHARM     V321   \n",
       "5845                   8           7.0            DEJA VU     T376   \n",
       "5846                   9           6.0        WINWIN RUBY     A120   \n",
       "5847                  10          13.0        WHOOP WHOOP     A096   \n",
       "5848                  11           3.0            UNICORN     T046   \n",
       "5849                  12           4.0          GOLD LAND     A109   \n",
       "5850                  13           1.0         LET US WIN     V381   \n",
       "5851                  14          12.0    PRETTY BAUHINIA     A135   \n",
       "5852                   1           6.0          TIME WARP     A066   \n",
       "5853                   2           3.0    BOOMING DELIGHT     A113   \n",
       "5854                   3           4.0     BEAT THE CLOCK     V397   \n",
       "5855                   4           2.0     ROMANTIC TOUCH     S393   \n",
       "5856                   5           7.0         KING GENKI     V181   \n",
       "5857                   6           5.0     SUPREME PROFIT     P230   \n",
       "5858                   7           1.0   HORSE OF FORTUNE     T118   \n",
       "5859                   8           8.0       ANTICIPATION     T198   \n",
       "5860                   1          11.0        CALCULATION     A248   \n",
       "5861                   2           2.0   CHUNG WAH SPIRIT     A168   \n",
       "5862                   3           4.0     FANTASTIC KAKA     P363   \n",
       "5863                   4          14.0   RIGHT HONOURABLE     A164   \n",
       "5864                   5          10.0       QUICK RETURN     A286   \n",
       "5865                   6           1.0          SUNNY WAY     V176   \n",
       "5866                   7           9.0       GOLDEN SLEEP     T117   \n",
       "5867                   8           6.0       WORLD RECORD     V040   \n",
       "5868                   9           7.0           INTREPIC     A139   \n",
       "5869                  10          12.0    HIGH AND MIGHTY     S362   \n",
       "5870                  11           3.0   DOUBLE VALENTINE     A163   \n",
       "5871                  12           8.0  THE JOY OF GIVING     A249   \n",
       "5872                  13           5.0         MIGHTY BOY     A352   \n",
       "\n",
       "            jockey       trainer  actual_weight  declared_horse_weight  draw  \\\n",
       "0          A Badel        W Y So            125                   1144    12   \n",
       "1       K K Chiong       P F Yiu            128                   1124     4   \n",
       "2        J Moreira      A S Cruz            133                   1131     9   \n",
       "3       S de Sousa       K L Man            132                   1064    11   \n",
       "4         O Murphy        T K Ng            121                   1075     5   \n",
       "5        M L Yeung         A Lee            130                   1203     1   \n",
       "6        K C Leung      R Gibson            129                   1237     2   \n",
       "7           C Y Ho       C H Yip            114                   1141     3   \n",
       "8           K C Ng        D Cruz            123                   1071     7   \n",
       "9         N Callan      R Gibson            126                   1124     9   \n",
       "10      K K Chiong        D Cruz            127                   1193     8   \n",
       "11        O Murphy        W Y So            131                   1090     1   \n",
       "12        K Teetan  D E Ferraris            120                   1073     2   \n",
       "13        Z Purton       C H Yip            122                   1056    12   \n",
       "14     C Schofield   A T Millard            122                   1064     3   \n",
       "15      M Chadwick      Y S Tsui            115                   1109     5   \n",
       "16      S de Sousa      A S Cruz            133                   1025     7   \n",
       "17       J Moreira      C Fownes            123                   1102    10   \n",
       "18         A Badel       K L Man            123                   1074     6   \n",
       "19       K C Leung          L Ho            124                   1156    11   \n",
       "20          C Y Ho        T K Ng            124                   1080     4   \n",
       "21     C Schofield   A T Millard            130                   1025     1   \n",
       "22      K K Chiong       K W Lui            123                   1175     7   \n",
       "23         A Badel      C S Shum            132                   1137     3   \n",
       "24       J Moreira        J Size            131                   1110     6   \n",
       "25      S de Sousa       P F Yiu            124                   1108    11   \n",
       "26       B Prebble        W Y So            124                   1128    12   \n",
       "27      M Chadwick     C W Chang            133                   1190     4   \n",
       "28       O Doleuze      C Fownes            123                   1068     9   \n",
       "29        Z Purton         A Lee            120                   1047     8   \n",
       "...            ...           ...            ...                    ...   ...   \n",
       "5843     M L Yeung        W Y So            114                   1100     5   \n",
       "5844       D Whyte     C W Chang            122                   1141     8   \n",
       "5845      H N Wong         A Lee            112                   1233     6   \n",
       "5846      N Callan       K L Man            129                   1036     3   \n",
       "5847       A Sanna       C H Yip            121                   1203     2   \n",
       "5848    K K Chiong      C S Shum            127                   1078     7   \n",
       "5849        C Y Ho      A S Cruz            129                   1146    13   \n",
       "5850  S Clipperton       J Moore            133                   1120    10   \n",
       "5851     U Rispoli      Y S Tsui            121                   1017    12   \n",
       "5852        K C Ng      A S Cruz            112                   1198     1   \n",
       "5853  S Clipperton       J Moore            123                   1183     8   \n",
       "5854     J Moreira        J Size            117                   1092     3   \n",
       "5855       D Whyte      A S Cruz            128                   1171     5   \n",
       "5856      K Teetan      A S Cruz            113                   1259     6   \n",
       "5857      M F Poon      C S Shum            108                   1279     4   \n",
       "5858      C Murray   A T Millard            133                   1094     7   \n",
       "5859     M L Yeung      A S Cruz            112                   1129     2   \n",
       "5860     J Moreira        J Size            120                   1076     7   \n",
       "5861      Z Purton       C H Yip            129                   1119     8   \n",
       "5862       A Sanna          L Ho            127                   1128     3   \n",
       "5863     M L Yeung      R Gibson            114                   1010     6   \n",
       "5864     U Rispoli      C S Shum            122                   1117     5   \n",
       "5865  S Clipperton       J Moore            131                   1053    14   \n",
       "5866    K K Chiong       C H Yip            117                   1170    10   \n",
       "5867      C Murray   A T Millard            127                   1073     4   \n",
       "5868      M F Poon      D J Hall            116                    993     2   \n",
       "5869       D Whyte        W Y So            119                   1132    11   \n",
       "5870     B Prebble      A S Cruz            127                   1085    13   \n",
       "5871       W M Lai     C W Chang            122                   1026     9   \n",
       "5872      N Callan       J Moore            126                   1153     1   \n",
       "\n",
       "     length_behind_winner      ...       finish_time  win_odds  \\\n",
       "0                       1      ...           0.57.79      90.0   \n",
       "1                       1      ...           0.57.82       3.7   \n",
       "2                   2-1/2      ...           0.58.07       5.9   \n",
       "3                       3      ...           0.58.12      11.0   \n",
       "4                   3-1/4      ...           0.58.18      19.0   \n",
       "5                       4      ...           0.58.28      17.0   \n",
       "6                   5-1/4      ...           0.58.48      18.0   \n",
       "7                       9      ...           0.59.11      87.0   \n",
       "8                  15-1/4      ...           1.00.08      47.0   \n",
       "9                       -      ...           1.10.69       6.0   \n",
       "10                     SH      ...           1.10.70      16.0   \n",
       "11                    1/2      ...           1.10.76       4.5   \n",
       "12                  1-1/4      ...           1.10.89       5.5   \n",
       "13                  1-1/4      ...           1.10.91      14.0   \n",
       "14                  1-1/2      ...           1.10.91      12.0   \n",
       "15                  1-1/2      ...           1.10.92      12.0   \n",
       "16                  1-1/2      ...           1.10.95       6.2   \n",
       "17                  4-1/2      ...           1.11.41       5.8   \n",
       "18                  8-1/2      ...           1.12.03      99.0   \n",
       "19                  9-1/4      ...           1.12.19      99.0   \n",
       "20                 13-1/4      ...           1.12.82      99.0   \n",
       "21                      -      ...           1.40.62       3.8   \n",
       "22                  2-1/4      ...           1.40.96      16.0   \n",
       "23                  2-1/2      ...           1.41.01      26.0   \n",
       "24                  2-3/4      ...           1.41.04       3.0   \n",
       "25                      5      ...           1.41.41      47.0   \n",
       "26                  5-1/4      ...           1.41.47       8.3   \n",
       "27                  5-1/2      ...           1.41.51      26.0   \n",
       "28                  5-3/4      ...           1.41.55      26.0   \n",
       "29                  6-1/4      ...           1.41.62       4.3   \n",
       "...                   ...      ...               ...       ...   \n",
       "5843                5-3/4      ...           1.36.87      30.0   \n",
       "5844                6-1/2      ...           1.36.98       8.4   \n",
       "5845                    7      ...           1.37.06      19.0   \n",
       "5846                    7      ...           1.37.08       4.7   \n",
       "5847                8-1/4      ...           1.37.27      38.0   \n",
       "5848                9-1/4      ...           1.37.42      23.0   \n",
       "5849                9-3/4      ...           1.37.50      30.0   \n",
       "5850               10-1/2      ...           1.37.61      14.0   \n",
       "5851               31-3/4      ...           1.41.03      12.0   \n",
       "5852                    -      ...           1.35.39       3.7   \n",
       "5853                1-3/4      ...           1.35.67       3.6   \n",
       "5854                3-1/2      ...           1.35.94       2.1   \n",
       "5855                3-3/4      ...           1.36.00      17.0   \n",
       "5856                4-1/4      ...           1.36.06      61.0   \n",
       "5857                6-1/4      ...           1.36.38      19.0   \n",
       "5858                6-1/4      ...           1.36.40      22.0   \n",
       "5859                   15      ...           1.37.80      32.0   \n",
       "5860                    -      ...           1.23.09       4.6   \n",
       "5861                1-3/4      ...           1.23.36       6.9   \n",
       "5862                    3      ...           1.23.51      17.0   \n",
       "5863                4-1/4      ...           1.23.74      49.0   \n",
       "5864                4-1/4      ...           1.23.74      12.0   \n",
       "5865                4-1/4      ...           1.23.76       7.9   \n",
       "5866                4-1/2      ...           1.23.79      79.0   \n",
       "5867                5-1/2      ...           1.23.98       8.4   \n",
       "5868                    6      ...           1.24.05       4.0   \n",
       "5869                6-3/4      ...           1.24.18       7.2   \n",
       "5870                9-1/4      ...           1.24.58      41.0   \n",
       "5871               13-1/2      ...           1.25.26      99.0   \n",
       "5872               14-1/4      ...           1.25.35      41.0   \n",
       "\n",
       "      running_position_5  running_position_6   race_id    recent_6_runs  \\\n",
       "0                    NaN                 NaN  2016-327              NaN   \n",
       "1                    NaN                 NaN  2016-327     4/11/2/1/5/8   \n",
       "2                    NaN                 NaN  2016-327    12/12/4/2/9/4   \n",
       "3                    NaN                 NaN  2016-327      2/9/3/4/1/3   \n",
       "4                    NaN                 NaN  2016-327      9/1/6/1/9/5   \n",
       "5                    NaN                 NaN  2016-327  11/11/8/10/9/12   \n",
       "6                    NaN                 NaN  2016-327   10/11/9/10/4/2   \n",
       "7                    NaN                 NaN  2016-327     11/10/12/7/9   \n",
       "8                    NaN                 NaN  2016-327    11/5/1/7/10/2   \n",
       "9                    NaN                 NaN  2016-328            4/3/3   \n",
       "10                   NaN                 NaN  2016-328     11/5/2/6/9/8   \n",
       "11                   NaN                 NaN  2016-328      2/4/4/5/7/5   \n",
       "12                   NaN                 NaN  2016-328      3/5/8/2/4/3   \n",
       "13                   NaN                 NaN  2016-328          6/14/12   \n",
       "14                   NaN                 NaN  2016-328      9/6/7/4/4/4   \n",
       "15                   NaN                 NaN  2016-328     6/2/8/9/4/12   \n",
       "16                   NaN                 NaN  2016-328     2/8/10/6/6/5   \n",
       "17                   NaN                 NaN  2016-328     11/1/2/3/6/7   \n",
       "18                   NaN                 NaN  2016-328             8/10   \n",
       "19                   NaN                 NaN  2016-328              NaN   \n",
       "20                   NaN                 NaN  2016-328               12   \n",
       "21                   NaN                 NaN  2016-329      1/2/2/7/4/6   \n",
       "22                   NaN                 NaN  2016-329    10/2/2/2/7/10   \n",
       "23                   NaN                 NaN  2016-329  10/12/10/12/6/2   \n",
       "24                   NaN                 NaN  2016-329      4/1/3/13/11   \n",
       "25                   NaN                 NaN  2016-329      7/7/6/1/2/3   \n",
       "26                   NaN                 NaN  2016-329      3/1/6/3/6/8   \n",
       "27                   NaN                 NaN  2016-329    9/5/2/12/2/12   \n",
       "28                   NaN                 NaN  2016-329      4/6/8/3/6/4   \n",
       "29                   NaN                 NaN  2016-329     1/9/12/7/6/9   \n",
       "...                  ...                 ...       ...              ...   \n",
       "5843                 NaN                 NaN  2016-803     7/8/4/12/6/6   \n",
       "5844                 NaN                 NaN  2016-803      9/2/2/4/6/6   \n",
       "5845                 NaN                 NaN  2016-803      5/5/5/7/5/6   \n",
       "5846                 NaN                 NaN  2016-803       1/8/6/4/14   \n",
       "5847                 NaN                 NaN  2016-803       11/14/5/13   \n",
       "5848                 NaN                 NaN  2016-803      4/3/2/3/8/1   \n",
       "5849                 NaN                 NaN  2016-803   8/7/10/8/11/11   \n",
       "5850                 NaN                 NaN  2016-803    10/4/3/9/14/9   \n",
       "5851                 NaN                 NaN  2016-803       10/7/7/4/9   \n",
       "5852                 NaN                 NaN  2016-804      1/1/7/4/6/3   \n",
       "5853                 NaN                 NaN  2016-804      1/2/2/8/1/1   \n",
       "5854                 NaN                 NaN  2016-804      1/1/2/1/3/2   \n",
       "5855                 NaN                 NaN  2016-804      2/6/3/3/8/2   \n",
       "5856                 NaN                 NaN  2016-804     11/1/1/3/7/2   \n",
       "5857                 NaN                 NaN  2016-804    9/3/7/9/12/10   \n",
       "5858                 NaN                 NaN  2016-804     1/2/9/10/8/6   \n",
       "5859                 NaN                 NaN  2016-804   2/13/8/5/11/14   \n",
       "5860                 NaN                 NaN  2016-805              NaN   \n",
       "5861                 NaN                 NaN  2016-805        4/1/7/3/7   \n",
       "5862                 NaN                 NaN  2016-805    7/4/14/9/2/11   \n",
       "5863                 NaN                 NaN  2016-805      8/3/7/11/12   \n",
       "5864                 NaN                 NaN  2016-805           10/6/5   \n",
       "5865                 NaN                 NaN  2016-805     4/3/5/2/1/12   \n",
       "5866                 NaN                 NaN  2016-805   1/11/10/11/5/6   \n",
       "5867                 NaN                 NaN  2016-805     3/4/3/1/11/2   \n",
       "5868                 NaN                 NaN  2016-805   1/2/12/13/13/6   \n",
       "5869                 NaN                 NaN  2016-805      5/3/9/8/9/9   \n",
       "5870                 NaN                 NaN  2016-805             8/11   \n",
       "5871                 NaN                 NaN  2016-805            12/10   \n",
       "5872                 NaN                 NaN  2016-805              NaN   \n",
       "\n",
       "      recent_ave_rank  jockey_ave_rank trainer_ave_rank race_distance  \n",
       "0                7.00                7                7          1000  \n",
       "1                5.17                7                7          1000  \n",
       "2                7.17                4                7          1000  \n",
       "3                3.67                6                7          1000  \n",
       "4                5.17                8                8          1000  \n",
       "5               10.17                7                7          1000  \n",
       "6                7.67                7                7          1000  \n",
       "7                9.80                7                7          1000  \n",
       "8                6.00                9                7          1000  \n",
       "9                3.33                6                7          1200  \n",
       "10               6.83                6                7          1200  \n",
       "11               4.50                8                7          1200  \n",
       "12               4.17                7                7          1200  \n",
       "13              10.67                5                7          1200  \n",
       "14               5.67                7                7          1200  \n",
       "15               6.83                7                7          1200  \n",
       "16               6.17                6                7          1200  \n",
       "17               5.00                4                7          1200  \n",
       "18               9.00                7                7          1200  \n",
       "19               7.00                7                7          1200  \n",
       "20              12.00                7                8          1200  \n",
       "21               3.67                7                7          1650  \n",
       "22               5.50                6                7          1650  \n",
       "23               8.67                7                7          1650  \n",
       "24               6.40                4                6          1650  \n",
       "25               4.33                6                7          1650  \n",
       "26               4.50                6                7          1650  \n",
       "27               7.00                7                8          1650  \n",
       "28               5.17                7                7          1650  \n",
       "29               7.33                5                7          1650  \n",
       "...               ...              ...              ...           ...  \n",
       "5843             7.17                7                7          1600  \n",
       "5844             4.83                6                8          1600  \n",
       "5845             5.50                8                7          1600  \n",
       "5846             6.60                6                7          1600  \n",
       "5847            10.75                9                7          1600  \n",
       "5848             3.50                7                7          1600  \n",
       "5849             9.17                8                6          1600  \n",
       "5850             8.17                7                6          1600  \n",
       "5851             7.40                7                7          1600  \n",
       "5852             3.67                9                6          1600  \n",
       "5853             2.50                7                6          1600  \n",
       "5854             1.67                4                5          1600  \n",
       "5855             4.00                6                6          1600  \n",
       "5856             4.17                7                6          1600  \n",
       "5857             8.33                5                7          1600  \n",
       "5858             6.00                7                7          1600  \n",
       "5859             8.83                7                6          1600  \n",
       "5860             7.00                4                5          1400  \n",
       "5861             4.40                5                7          1400  \n",
       "5862             7.83                9                7          1400  \n",
       "5863             8.20                7                7          1400  \n",
       "5864             7.00                7                7          1400  \n",
       "5865             4.50                7                6          1400  \n",
       "5866             7.33                7                7          1400  \n",
       "5867             4.00                7                7          1400  \n",
       "5868             7.83                5                7          1400  \n",
       "5869             7.17                6                7          1400  \n",
       "5870             9.50                6                6          1400  \n",
       "5871            11.00                9                8          1400  \n",
       "5872             7.00                6                6          1400  \n",
       "\n",
       "[5873 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('data/testing.csv')\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:30: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:31: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "# prepare training data\n",
    "for i in range(m_train):\n",
    "    train_horse[i,0] = horse.index(df_train.horse_name[i])\n",
    "    train_jockey[i,0] = jockey.index(df_train.jockey[i])\n",
    "    train_trainer[i,0] = trainer.index(df_train.trainer[i])\n",
    "actual_weight = df_train.actual_weight.reshape((m_train,1))\n",
    "declared_weight = df_train.declared_horse_weight.reshape((m_train,1))\n",
    "draw = df_train.draw.reshape((m_train,1))\n",
    "win_odds = df_train.win_odds.reshape((m_train,1))\n",
    "race_distance = df_train.race_distance.reshape((m_train,1))\n",
    "\n",
    "# we use horse, jockey, trainer, actual weight, declared weight, win odds, race distance as independent variables\n",
    "X_train = np.hstack((train_horse, train_jockey, train_trainer, actual_weight,\n",
    "                     declared_weight, draw, win_odds, race_distance)) \n",
    "y_train = df_train.finishing_position\n",
    "\n",
    "# prepare test data\n",
    "test_horse=np.zeros((m_test,1))\n",
    "test_jockey=np.zeros((m_test,1))\n",
    "test_trainer=np.zeros((m_test,1))\n",
    "\n",
    "#print(df_test.horse_name[])\n",
    "for i in range(len(df_test)):\n",
    "    test_horse[i,0] = horse.index(df_test.horse_name[i])\n",
    "    test_jockey[i,0] = jockey.index(df_test.jockey[i])\n",
    "    test_trainer[i,0] = trainer.index(df_test.trainer[i])\n",
    "actual_weight_test = df_test.actual_weight.reshape((m_test,1))\n",
    "declared_weight_test = df_test.declared_horse_weight.reshape((m_test,1))\n",
    "draw_test = df_test.draw.reshape((m_test,1))\n",
    "win_odds_test = df_test.win_odds.reshape((m_test,1))\n",
    "race_distance_test = df_test.race_distance.reshape((m_test,1))\n",
    "X_test = np.hstack((test_horse,test_jockey,test_trainer,actual_weight_test,\n",
    "                    declared_weight_test, draw_test, win_odds_test, race_distance_test))\n",
    "y_test = df_test.finishing_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1.1 Logistic\n",
    "start_time = time.time()\n",
    "lr_model = LogisticRegression(C=0.1, random_state=0)\n",
    "lr_model.fit(X_train,y_train)\n",
    "lr_result = lr_model.predict(X_test)\n",
    "print('training time: ', time.time()-start_time, 'secends')\n",
    "# print(lr_result.shape)\n",
    "lr_score = lr_model.score(X_test,y_test)\n",
    "print(lr_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('start')\n",
    "parameters = {'penalty': ['l1', 'l2'], 'C': [0.06, 0.08, 0.1, 1], 'random_state': [0]}\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(clf.cv_results_)\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_params_)\n",
    "lr_new = clf.best_estimator_\n",
    "lr_new.fit(X_train,y_train)\n",
    "print(lr_new.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.2 NaÃ¯ve Bayes\n",
    "start_time = time.time()\n",
    "nb_model = sklearn.naive_bayes.GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_result=nb_model.predict(X_test)\n",
    "print('training time: ', time.time()-start_time, 'secends')\n",
    "nb_score = nb_model.score(X_test, y_test)\n",
    "print(nb_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from naive_bayes import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-068048c2f588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = NaiveBayes()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.3 SVM\n",
    "# first normalize the data\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC(kernel='rbf',random_state=0,gamma=0.005,C=0.7)\n",
    "#print('model')\n",
    "#svm_model.fit(X_train, y_train)\n",
    "#print('fit')\n",
    "#svm_score = svm_model.score(X_test, y_test)\n",
    "#print(svm_score)\n",
    "start_time = time.time()\n",
    "#print('model')\n",
    "svm_model.fit(X_train, y_train)\n",
    "#print('fit')\n",
    "svm_result=svm_model.predict(X_test)\n",
    "print('training time: ', time.time()-start_time, 'secends')\n",
    "svm_score = svm_model.score(X_test, y_test)\n",
    "#print(svm_model.coef_)\n",
    "#print(svm_model.predict(X_test))\n",
    "print(svm_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape\n",
    "X_train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_X=StandardScaler()\n",
    "scaler_X.fit(X_train)\n",
    "X_train_normalized=scaler_X.transform(X_train)\n",
    "scaler_X.fit(X_test)\n",
    "X_test_normalized=scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y=StandardScaler()\n",
    "scaler_y.fit(y_train.reshape(-1, 1))\n",
    "y_train_normalized=scaler_y.transform(y_train.reshape(-1, 1))\n",
    "scaler_y.fit(y_test.reshape(-1, 1))\n",
    "y_test_normalized=scaler_y.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':['rbf', 'poly'], 'C':[0.1, 0.5, 1], 'gamma': ['auto', 0.01, 0.1], \n",
    "              'random_state': [0], 'max_iter': [100, 500, 1000]}\n",
    "svc = svm.SVC()\n",
    "print('start training')\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train_normalized, y_train_normalized)\n",
    "print('finish')\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)\n",
    "svm_new = clf.best_estimator_\n",
    "svm_new.fit(X_train_normalized,y_train_normalized)\n",
    "print(svm_new.score(X_test_normalized, y_test_normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('start')\n",
    "parameters = {'n_estimators': [30, 50, 100], 'max_features': ['sqrt', 'log2', None], \n",
    "              'max_depth': [None,1, 2, 5], 'random_state': [0]}\n",
    "raf = RandomForestClassifier()\n",
    "clf = GridSearchCV(raf, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print('finish')\n",
    "sorted(clf.cv_results_.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)\n",
    "raf_new = clf.best_estimator_\n",
    "raf_new.fit(X_train,y_train)\n",
    "print(raf_new.score(X_test, y_test))\n",
    "print(clf.best_estimator_)\n",
    "print(raf_new.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3.1.4 Random Forest\n",
    "\n",
    "start_time = time.time()\n",
    "rf_model=RandomForestClassifier(max_depth=2,random_state=0)\n",
    "\n",
    "rf_model.fit(X_train,y_train)\n",
    "rf_result=rf_model.predict(X_test)\n",
    "print('training time: ', time.time()-start_time, 'secends')\n",
    "#print(rf_model.predict(X_test))\n",
    "print(rf_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2\n",
    "from collections import Counter\n",
    "#The lr matrix\n",
    "horse_win_lr=np.zeros((len(lr_result),1))\n",
    "horse_top3_lr=np.zeros((len(lr_result),1))\n",
    "horse_top50percent_lr=np.zeros((len(lr_result),1))\n",
    "count_of_race_participation=Counter(df_test.race_id)\n",
    "for i in range(len(lr_result)):\n",
    "    if lr_result[i] == 1:\n",
    "         horse_win_lr[i]=1\n",
    "    if lr_result[i] <= 3:\n",
    "         horse_top3_lr[i] = 1\n",
    "    if lr_result[i]<= np.floor(count_of_race_participation[df_test.race_id[i]]/2):\n",
    "         horse_top50percent_lr[i] = 1\n",
    "headers=['RaceID','HorseID','HorseWin','HorseRankTop3','HorseRankTop50Percent']\n",
    "import csv\n",
    "with open('lr_predictions.csv','w') as f1:\n",
    "     lr_csv=csv.writer(f1)\n",
    "     lr_csv.writerow(headers)\n",
    "     for i in range(len(lr_result)):\n",
    "         lr_csv.writerow([df_test.race_id[i],df_test.horse_id[i],horse_win_lr[i][0],horse_top3_lr[i][0],horse_top50percent_lr[i][0]])\n",
    "#the naive bayesian matrix\n",
    "horse_win_nb=np.zeros((len(nb_result),1))\n",
    "horse_top3_nb=np.zeros((len(nb_result),1))\n",
    "horse_top50percent_nb=np.zeros((len(nb_result),1))\n",
    "count_of_race_participation=Counter(df_test.race_id)\n",
    "for i in range(len(nb_result)):\n",
    "    if nb_result[i] == 1:\n",
    "        horse_win_nb[i]=1\n",
    "    if nb_result[i] <= 3:\n",
    "        horse_top3_nb[i] = 1\n",
    "    if nb_result[i]<= np.floor(count_of_race_participation[df_test.race_id[i]]/2):\n",
    "        horse_top50percent_nb[i] = 1\n",
    "with open('nb_predictions.csv','w') as f2:\n",
    "     nb_csv=csv.writer(f2)\n",
    "     nb_csv.writerow(headers)\n",
    "     for i in range(len(nb_result)):\n",
    "         nb_csv.writerow([df_test.race_id[i],df_test.horse_id[i],horse_win_nb[i][0],horse_top3_nb[i][0],horse_top50percent_nb[i][0]])\n",
    "#the svm matrix\n",
    "horse_win_svm=np.zeros((len(svm_result),1))\n",
    "horse_top3_svm=np.zeros((len(svm_result),1))\n",
    "horse_top50percent_svm=np.zeros((len(svm_result),1))\n",
    "count_of_race_participation=Counter(df_test.race_id)\n",
    "for i in range(len(svm_result)):\n",
    "    if svm_result[i] == 1:\n",
    "        horse_win_svm[i]=1\n",
    "    if svm_result[i] <= 3:\n",
    "        horse_top3_svm[i] = 1\n",
    "    if svm_result[i]<= np.floor(count_of_race_participation[df_test.race_id[i]]/2):\n",
    "        horse_top50percent_svm[i] = 1\n",
    "with open('svm_predictions.csv','w') as f3:\n",
    "    svm_csv=csv.writer(f3)\n",
    "    svm_csv.writerow(headers)\n",
    "    for i in range(len(svm_result)):\n",
    "        svm_csv.writerow([df_test.race_id[i],df_test.horse_id[i],horse_win_svm[i][0],horse_top3_svm[i][0],horse_top50percent_svm[i][0]])\n",
    "#the rf matrix\n",
    "horse_win_rf=np.zeros((len(rf_result),1))\n",
    "horse_top3_rf=np.zeros((len(rf_result),1))\n",
    "horse_top50percent_rf=np.zeros((len(rf_result),1))\n",
    "count_of_race_participation=Counter(df_test.race_id)\n",
    "for i in range(len(rf_result)):\n",
    "    if rf_result[i] == 1:\n",
    "        horse_win_rf[i]=1\n",
    "    if rf_result[i] <= 3:\n",
    "        horse_top3_rf[i] = 1\n",
    "    if rf_result[i]<= np.floor(count_of_race_participation[df_test.race_id[i]]/2):\n",
    "        horse_top50percent_rf[i] = 1\n",
    "with open('rf_predictions.csv','w') as f4:\n",
    "    rf_csv=csv.writer(f4)\n",
    "    rf_csv.writerow(headers)\n",
    "    for i in range(len(rf_result)):\n",
    "        rf_csv.writerow([df_test.race_id[i],df_test.horse_id[i],horse_win_rf[i][0],horse_top3_rf[i][0],horse_top50percent_rf[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.3\n",
    "#get actual results from y_test\n",
    "horse_win_actual=np.zeros((len(y_test),1))\n",
    "horse_top3_actual=np.zeros((len(y_test),1))\n",
    "horse_top50percent_actual=np.zeros((len(y_test),1))\n",
    "count_of_race_participation=Counter(df_test.race_id)\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i]==1:\n",
    "         horse_win_actual[i]=1\n",
    "    if y_test[i]<=3:\n",
    "         horse_top3_actual[i]=1\n",
    "    if y_test[i]<=np.floor(count_of_race_participation[df_test.race_id[i]]/2):\n",
    "         horse_top50percent_actual[i]=1\n",
    "#lr model\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr horse_win\n",
    "    if (horse_win_lr[i]==1 and horse_win_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_win_lr[i]==1 and horse_win_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_win_lr[i]==0 and horse_win_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_win_lr[i]==0 and horse_win_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of logistic model horse_win prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of logistic model horse_win prediction= \", TP/(TP+FP))\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr_top3\n",
    "    if (horse_top3_lr[i]==1 and horse_top3_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_top3_lr[i]==1 and horse_top3_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_top3_lr[i]==0 and horse_top3_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_top3_lr[i]==0 and horse_top3_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of logistic model horse_top3 prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of logistic model horse_top3 prediction= \", TP/(TP+FP))\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr_top50percent\n",
    "    if (horse_top50percent_lr[i]==1 and horse_top50percent_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_top50percent_lr[i]==1 and horse_top50percent_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_top50percent_lr[i]==0 and horse_top50percent_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_top50percent_lr[i]==0 and horse_top50percent_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of logistic model horse_top50percent prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of logistic model horse_top50percent prediction= \", TP/(TP+FP))\n",
    "#naive bayesian\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#nb horse_win\n",
    "    if (horse_win_nb[i]==1 and horse_win_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_win_nb[i]==1 and horse_win_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_win_nb[i]==0 and horse_win_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_win_nb[i]==0 and horse_win_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of naive bayesian model horse_win prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of naive bayesian model horse_win prediction= \", TP/(TP+FP))\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr_top3\n",
    "    if (horse_top3_nb[i]==1 and horse_top3_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_top3_nb[i]==1 and horse_top3_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_top3_nb[i]==0 and horse_top3_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_top3_nb[i]==0 and horse_top3_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of naive bayesian model horse_top3 prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of naive bayesian model horse_top3 prediction= \", TP/(TP+FP))\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr_top50percent\n",
    "    if (horse_top50percent_nb[i]==1 and horse_top50percent_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_top50percent_nb[i]==1 and horse_top50percent_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_top50percent_nb[i]==0 and horse_top50percent_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_top50percent_nb[i]==0 and horse_top50percent_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of naive bayesian model horse_top50percent prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of naive bayesian model horse_top50percent prediction= \", TP/(TP+FP))\n",
    "#svm\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#nb horse_win\n",
    "    if (horse_win_svm[i]==1 and horse_win_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_win_svm[i]==1 and horse_win_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_win_svm[i]==0 and horse_win_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_win_svm[i]==0 and horse_win_actual[i]==0):\n",
    "        TN=TN+1\n",
    "if ((TP+FN)==0 or (TP+FP)==0):\n",
    "    print(\"Recall of svm model horse_win prediction and Precision of svm model horse_win prediction= 0\")\n",
    "else:\n",
    "    print(\"Recall of svm model horse_win prediction= \", TP/(TP+FN))\n",
    "    print(\"Precision of svm model horse_win prediction= \", TP/(TP+FP))\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr_top3\n",
    "    if (horse_top3_svm[i]==1 and horse_top3_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_top3_svm[i]==1 and horse_top3_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_top3_svm[i]==0 and horse_top3_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_top3_svm[i]==0 and horse_top3_actual[i]==0):\n",
    "        TN=TN+1\n",
    "if ((TP+FN)==0 or (TP+FP)==0):\n",
    "     print(\"Recall of svm model horse_top3 prediction and Precision of svm model horse_top3 prediction= 0\")\n",
    "else:\n",
    "     print(\"Recall of svm model horse_top3 prediction= \", TP/(TP+FN))\n",
    "     print(\"Precision of svm model horse_top3 prediction= \", TP/(TP+FP))\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr_top50percent\n",
    "    if (horse_top50percent_svm[i]==1 and horse_top50percent_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_top50percent_svm[i]==1 and horse_top50percent_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_top50percent_svm[i]==0 and horse_top50percent_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_top50percent_svm[i]==0 and horse_top50percent_actual[i]==0):\n",
    "        TN=TN+1\n",
    "if ((TP+FN)==0 or (TP+FP)==0):\n",
    "     print(\"Recall of svm model horse_top50percent prediction and Precision of svm model horse_top50percent prediction= 0\")\n",
    "else:\n",
    "     print(\"Recall of svm model horse_top50percent prediction= \", TP/(TP+FN))\n",
    "     print(\"Precision of svm model horse_top50percent prediction= \", TP/(TP+FP))\n",
    "#rf model\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#nb horse_win\n",
    "    if (horse_win_rf[i]==1 and horse_win_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_win_rf[i]==1 and horse_win_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_win_rf[i]==0 and horse_win_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_win_rf[i]==0 and horse_win_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of rf model horse_win prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of rf model horse_win prediction= \", TP/(TP+FP))\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr_top3\n",
    "    if (horse_top3_rf[i]==1 and horse_top3_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_top3_rf[i]==1 and horse_top3_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_top3_rf[i]==0 and horse_top3_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_top3_rf[i]==0 and horse_top3_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of rf model horse_top3 prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of rf model horse_top3 prediction= \", TP/(TP+FP))\n",
    "TP=0;FP=0;FN=0;TN=0\n",
    "for i in range(len(X_test)):#lr_top50percent\n",
    "    if (horse_top50percent_rf[i]==1 and horse_top50percent_actual[i]==1):\n",
    "        TP=TP+1\n",
    "    if (horse_top50percent_rf[i]==1 and horse_top50percent_actual[i]==0):\n",
    "        FP=FP+1\n",
    "    if (horse_top50percent_rf[i]==0 and horse_top50percent_actual[i]==1):\n",
    "        FN=FN+1\n",
    "    if (horse_top50percent_rf[i]==0 and horse_top50percent_actual[i]==0):\n",
    "        TN=TN+1\n",
    "print(\"Recall of rf model horse_top50percent prediction= \", TP/(TP+FN))\n",
    "print(\"Precision of rf model horse_top50percent prediction= \", TP/(TP+FP))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
